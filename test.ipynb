{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22137da8",
   "metadata": {},
   "source": [
    "###### First Step is to download the CIFAR10 dataset (binary version used by Raptor-NN) to be used for quantizing and exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "../Shared/download_cifar10_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf56c8",
   "metadata": {},
   "source": [
    "## 1. First Workflow\n",
    "### 1.1. Training the model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e3d79",
   "metadata": {},
   "source": [
    "We start by importing packages that we're going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c69a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras_model_def import resnet_v1\n",
    "from data_loader import load_cifar_10_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad0dc0d",
   "metadata": {},
   "source": [
    "We then define global parameters that can be used when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Shared/cifar-10-batches-py/\"\n",
    "num_classes = 10\n",
    "num_filters = 16\n",
    "image_size = 32\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "resume_train = False\n",
    "optimizer_name = \"adam\"\n",
    "model_save_dir = \"img_cls_trained_model_adam_10epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading either an already trained model or instantiate a new one\n",
    "if resume_train:\n",
    "    keras_model = tf.keras.models.load_model(os.path.join('trained_models', model_save_dir)) \n",
    "else: \n",
    "    keras_model = resnet_v1(input_shape=[image_size, image_size, 3], \n",
    "                num_classes=num_classes, num_filters=num_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the model summary\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training and test data using a custom loader\n",
    "train_data, train_labels, test_data, test_labels = load_cifar_10_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying data augmentation (transformations) using Keras's ImageDataGenerator\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                rotation_range=10,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                horizontal_flip=True,\n",
    "                                rescale=1./255\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the train and validation generators\n",
    "train_generator = datagen.flow(train_data, train_labels, batch_size=batch_size)\n",
    "valid_generator = datagen.flow(test_data, test_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an optimizer to be used for training (commonly used ones are SGD and Adam)\n",
    "if optimizer_name == \"sgd\":\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, name='SGD')\n",
    "else:\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36672758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and metrics for this network\n",
    "loss_func = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model for training\n",
    "keras_model.compile(optimizer=optimizer, loss=loss_func, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36780e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the training of the model for a certain number of epochs\n",
    "history = keras_model.fit(\n",
    "            train_generator,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(train_generator),\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=len(valid_generator),\n",
    "            shuffle=True,\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1753bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and saving accuracy/loss curves\n",
    "plt.plot(np.array(range(num_epochs)), history.history['loss'])\n",
    "plt.plot(np.array(range(num_epochs)), history.history['accuracy'])\n",
    "plt.savefig('tf_loss_accuracy_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to a directory\n",
    "keras_model.save(os.path.join('trained_models', model_save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8710c63",
   "metadata": {},
   "source": [
    "### 1.2. Exporting the model with Raptor-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f899dcd",
   "metadata": {},
   "source": [
    "We start by importing packages that we're going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00433c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_to_n2d2\n",
    "import n2d2\n",
    "import n2d2_ip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d73c5",
   "metadata": {},
   "source": [
    "We then define global parameters that can be used when exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d797dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Shared/cifar-10-batches-bin/\"\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "saved_model_dir = \"img_cls_trained_model_adam_2epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048aae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) We can load an already trained Keras model to be wrapped by Raptor-NN\n",
    "keras_model = tf.keras.models.load_model(os.path.join('trained_models', saved_model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7501ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the Keras model with N2D2 Backend\n",
    "raptor_model = keras_to_n2d2.wrap(keras_model, batch_size=batch_size,\n",
    "                            name=\"resnet_model\", for_export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7354e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CIFAR10 database that will be used for calibration / quantization (test = 1 - learn - validation).\n",
    "db = n2d2.database.CIFAR10()\n",
    "db.load(data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the train, validation and test partition summary\n",
    "db.get_partition_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8187a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the data provider for data loading\n",
    "provider = n2d2.provider.DataProvider(db, [image_size, image_size, 3],\n",
    "                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of transformations that will be applied to images when loading\n",
    "\n",
    "# Converting the images color space from BGR to RGB (Raptor-NN reads images in BGR format by default)\n",
    "provider.add_transformation(n2d2.transform.ColorSpace(color_space=\"RGB\"))\n",
    "\n",
    "# Applying a transformation (Rescaling) as preprocessing\n",
    "provider.add_transformation(n2d2.transform.RangeAffine(first_operator=\"Divides\", first_value=255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88899008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning the DeepnetCell that can be exported \n",
    "raptor_deepnet_cell = raptor_model.get_deepnet_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ec661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Removing Softmax layer (not supported) for CPP export\n",
    "raptor_deepnet_cell.remove(raptor_deepnet_cell[-1].get_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db285d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantizing the network using PTQ (Post Training Quantization) quantizer\n",
    "n2d2.quantizer.PTQ(\n",
    "            raptor_deepnet_cell,\n",
    "            provider=provider,\n",
    "            nb_bits=8,\n",
    "            nb_sitmuli=2000,\n",
    "            no_unsigned=True,\n",
    "            act_scaling_mode=\"SINGLE_SHIFT\",\n",
    "            export_no_cross_layer_equalization=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29684a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter for choosing the TinyRaptor export version\n",
    "export_version = \"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec968bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the HW configuration file depending on the export version\n",
    "if export_version == \"v2\":\n",
    "    npu_params_file = \"../Shared/npu_params_v2.ini\"\n",
    "else:\n",
    "    npu_params_file = \"../Shared/npu_params_v1.ini\"\n",
    "    \n",
    "# Generating TinyRaptor Export\n",
    "n2d2_ip.export.export_PNasm(\n",
    "    raptor_deepnet_cell,\n",
    "    npu_params_path=npu_params_file,\n",
    "    export_nb_stimuli_max=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13927761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating reference export (CPP)\n",
    "n2d2.export.export_cpp(\n",
    "    raptor_deepnet_cell,\n",
    "    export_nb_stimuli_max=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f759243",
   "metadata": {},
   "source": [
    "## 2. Second Workflow\n",
    "### 2.1. Training the model with RaptorNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea65e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "255d1da5",
   "metadata": {},
   "source": [
    "### 2.2. Exporting the model with RaptorNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded74045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
